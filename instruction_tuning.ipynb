{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqyWJ5uUMN768ZCkH7Nere",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GrimbleGrien/Instruction-Tuning-Transformers/blob/main/instruction_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mMLDdQY7xbVF"
      }
    },
    {
      "source": [
        "!pip install tweet-preprocessor datasets peft"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "QROEFbPYPFeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python data_preparation.py \\\n",
        "--train train_caves.csv \\\n",
        "--test test_caves.csv \\\n",
        "--out_dir dataset_instruct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_8ncf9Boo1w",
        "outputId": "59bbb1e6-19a0-478b-cf87-4e495c81cad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed train file saved to dataset_instruct/train_instruct.csv\n",
            "Processed test file saved to dataset_instruct/test_instruct.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tuning_lora.py \\\n",
        "    --model_name \"google/flan-t5-base\" \\\n",
        "    --tokenizer_name \"google/flan-t5-base\" \\\n",
        "    --text_column \"input\" \\\n",
        "    --label_column \"target\" \\\n",
        "    --max_length 128 \\\n",
        "    --batch_size 8 \\\n",
        "    --output_path \"./flan-t5-base-5e.txt\" \\\n",
        "    --output_dir \"./dataset_instruct\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB8uMamIph1h",
        "outputId": "81b8d244-8752-4297-9e3d-c2d527ba776c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-30 17:56:36.669312: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-30 17:56:36.688681: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-30 17:56:36.694711: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-30 17:56:36.709923: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-30 17:56:37.989757: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "tokenizer_config.json: 100% 2.54k/2.54k [00:00<00:00, 16.9MB/s]\n",
            "spiece.model: 100% 792k/792k [00:00<00:00, 57.7MB/s]\n",
            "tokenizer.json: 100% 2.42M/2.42M [00:00<00:00, 43.8MB/s]\n",
            "special_tokens_map.json: 100% 2.20k/2.20k [00:00<00:00, 14.8MB/s]\n",
            "Running tokenizer on training dataset: 100% 6957/6957 [00:03<00:00, 1804.23 examples/s]\n",
            "Running tokenizer on test dataset: 100% 1977/1977 [00:00<00:00, 2345.22 examples/s]\n",
            "config.json: 100% 1.40k/1.40k [00:00<00:00, 8.86MB/s]\n",
            "model.safetensors: 100% 990M/990M [00:10<00:00, 90.5MB/s]\n",
            "generation_config.json: 100% 147/147 [00:00<00:00, 630kB/s]\n",
            "trainable params: 221,184 || all params: 247,799,040 || trainable%: 0.0893\n",
            "{'loss': 0.5652, 'grad_norm': 1.2729806900024414, 'learning_rate': 0.00044252873563218394, 'epoch': 0.57}\n",
            "{'loss': 0.1142, 'grad_norm': 1.8881864547729492, 'learning_rate': 0.0003850574712643678, 'epoch': 1.15}\n",
            "{'loss': 0.0908, 'grad_norm': 0.3883003890514374, 'learning_rate': 0.0003275862068965517, 'epoch': 1.72}\n",
            "{'loss': 0.0815, 'grad_norm': 0.8931655883789062, 'learning_rate': 0.0002701149425287356, 'epoch': 2.3}\n",
            "{'loss': 0.0739, 'grad_norm': 0.34125739336013794, 'learning_rate': 0.00021264367816091953, 'epoch': 2.87}\n",
            "{'loss': 0.0675, 'grad_norm': 0.5946394205093384, 'learning_rate': 0.00015517241379310346, 'epoch': 3.45}\n",
            "{'loss': 0.0641, 'grad_norm': 0.5158897042274475, 'learning_rate': 9.770114942528736e-05, 'epoch': 4.02}\n",
            "{'loss': 0.0627, 'grad_norm': 0.608618438243866, 'learning_rate': 4.0229885057471265e-05, 'epoch': 4.6}\n",
            "{'train_runtime': 1131.4988, 'train_samples_per_second': 30.742, 'train_steps_per_second': 3.844, 'train_loss': 0.13342159841252468, 'epoch': 5.0}\n",
            "100% 4350/4350 [18:51<00:00,  3.84it/s]\n",
            "config.json: 100% 1.40k/1.40k [00:00<00:00, 9.10MB/s]\n",
            "100% 248/248 [00:29<00:00,  8.29it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python label_matcher.py \\\n",
        "--model \"all-MiniLM-L6-v2\" \\\n",
        "--output_path \"./flan-t5-base-5e.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRhZFhvm0K6X",
        "outputId": "74327fe8-69fe-4435-95d6-4ba90590b68d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-30 18:59:41.093023: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-30 18:59:41.113029: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-30 18:59:41.119044: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-30 18:59:41.133369: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-30 18:59:42.352622: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "1000th iteration\n",
            "F1 Macro: 0.8521715454461459\n",
            "F1 Micro: 0.8835745752045312\n",
            "Accuracy: 0.7440566514921598\n",
            "Jaccard Score: 0.8159554699777809, Weighted F1: 0.8894766565489202\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  conspiracy       0.57      1.00      0.73        97\n",
            "     country       1.00      0.97      0.99        40\n",
            " ineffective       1.00      0.99      0.99       334\n",
            " ingredients       1.00      0.80      0.89        87\n",
            "   mandatory       0.99      0.94      0.96       157\n",
            "        none       0.98      1.00      0.99       126\n",
            "      pharma       0.88      0.90      0.89       255\n",
            "   political       0.93      0.70      0.80       125\n",
            "   religious       0.78      0.54      0.64        13\n",
            "      rushed       0.98      0.84      0.91       295\n",
            " side-effect       1.00      0.83      0.91       762\n",
            " unnecessary       0.47      0.61      0.53       145\n",
            "\n",
            "   micro avg       0.90      0.86      0.88      2436\n",
            "   macro avg       0.88      0.84      0.85      2436\n",
            "weighted avg       0.93      0.86      0.89      2436\n",
            " samples avg       0.94      0.92      0.91      2436\n",
            "\n"
          ]
        }
      ]
    }
  ]
}